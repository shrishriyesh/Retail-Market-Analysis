{
  "metadata": {
    "name": "Instacart-data-ingestion",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Step 1: Data Loading"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val aislesDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/aisles.csv\")\nval departmentsDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/departments.csv\")\nval productsDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/products.csv\")\nval ordersDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/orders.csv\")\n\nval priorsDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/order_products__prior.csv\")\nval trainDF \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"instacart/order_products__train.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(aislesDF)\nz.show(departmentsDF)\nz.show(productsDF)\nz.show(ordersDF)\n\nz.show(priorsDF)\nz.show(trainDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Step 2: Data Profiling\n\n1. __Aisles__: Contains a one-to-one mapping between a unique Aisle ID and the Aisle Name\n2. __Departments__: Contains a one-to-one mapping between a unique Department ID and the Department Name\n3. __Products__: Contains a one-to-one mapping between a unique Product ID and the Product Name. Each Product also has an Aisle ID and a Department ID\n\nThe Aisle Name and Department Name act different categorization fields for each Product"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"Aisles DF\")\naislesDF.printSchema()\n\nprintln(\"Departments DF\")\ndepartmentsDF.printSchema()\n\nprintln(\"Products DF\")\nproductsDF.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "4. __Orders__: Contains information of a particular order. Fields include -\n    - *User ID*: Unique ID for a particular Instacart user\n    - *Order Number*: The order number for a particular user\n    - *Order DOW*: The Day of the Week that the order was placed\n    - *Order Hour of Day*: The hour of day when the order was placed\n    - *Days Since Prior Order*: The number of days since the previous order after which this order was placed"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"Orders DF\")\nordersDF.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "5. __Priors__: Contains Order History of every user\n6. __Train__: Training Data provided by Instacart\n\nBoth these datasets have the same set of columns:\n    - *Order ID*: Unique order id for every order\n    - *Product ID*: product ID of item purchased in the order\n    - *Add to cart order*: denotes the sequence in which products were added to cart\n    - *Reordered*: Is the product reordered? (0/1)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"Priors DF\")\npriorsDF.printSchema()\n\nprintln(\"Train DF\")\ntrainDF.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1. Dataset Size\n\nCalculating Dataset sizes and answering questions on the dataset"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val aislesCount \u003d aislesDF.count()\nval departmentsCount \u003d departmentsDF.count()\nval productsCount \u003d productsDF.count()\nval ordersCount \u003d ordersDF.count()\n\nval priorsCount \u003d priorsDF.count()\nval trainCount \u003d trainDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(s\"Number of aisles: ${aislesCount}\")\nprintln(s\"Number of departments: ${departmentsCount}\")\nprintln(s\"Number of products: ${productsCount}\")\nprintln(s\"Number of orders: ${ordersCount}\")\n\nprintln(s\"Number of order history records: ${priorsCount}\")\nprintln(s\"Number of training order records: ${trainCount}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val uniqueOrderCount \u003d ordersDF.select(\"order_id\").distinct().count()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(s\"Are all orders unique? ${ordersCount \u003d\u003d uniqueOrderCount}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2. Null Checks\n\nCheck columns for null values in all fields"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nullAisles \u003d aislesDF.filter($\"aisle_id\".isNull || $\"aisle\".isNull).count()\nval nullDepartments \u003d departmentsDF.filter($\"department_id\".isNull || $\"department\".isNull).count()\nval nullProducts \u003d productsDF.filter($\"product_id\".isNull || $\"product_name\".isNull || $\"aisle_id\".isNull || $\"department_id\".isNull).count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "__Orders Dataframe__ is expected to have null values in case there is no previous order (`days_since_prior_order \u003d null`)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val firstTimeOrders \u003d ordersDF.filter($\"days_since_prior_order\".isNull).count"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val orderColumns \u003d ordersDF.columns.filter(col \u003d\u003e col !\u003d \"days_since_prior_order\")\nval nullOrders \u003d ordersDF.filter(orderColumns.map(c \u003d\u003e col(c).isNull).reduce(_ || _)).count"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nullPriors \u003d priorsDF.filter(priorsDF.columns.map(c \u003d\u003e col(c).isNull).reduce(_ || _)).count\nval nullTrains \u003d trainDF.filter(trainDF.columns.map(c \u003d\u003e col(c).isNull).reduce(_ || _)).count"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3. Column Statistics\n\nSimple summary statistics for each column of the __Order__ Dataframe"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(ordersDF.summary())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Step 3: Data Preprocessing\n\nThe data from different sources need to be preprocessed and merged to perform further data profiling"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1. Join the smaller tables to get Product Details\n\nCreate the `productDetailsDF` by joining `productsDF`, `aislesDF` and `departmentsDF`\n\nWe notice that one of the products does not have a corresponding Aisle and Department name"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDF \u003d productsDF.join(broadcast(aislesDF), Seq(\"aisle_id\"), \"left_outer\")\nval productDetailsDF \u003d joinedDF.join(broadcast(departmentsDF), Seq(\"department_id\"), \"left_outer\")"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(productDetailsDF.filter($\"aisle\".isNull || $\"department\".isNull))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2. Merge the __Prior__ and the __Train__ datasets\n\nSince we are not concerned if the order_products record comes from `train.csv` or `prior.csv`, we can merge the two datasets into a single bigger dataset"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val orderProductsDF \u003d priorsDF.union(trainDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(s\"Does the merged dataset have distinct items? ${orderProductsDF.count.equals(orderProductsDF.distinct.count)}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3. Remove null from Orders\n\n`ordersDF` has pre-existing null values in the `days_since_prior_order` column. These can be filled with -1."
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val updatedOrdersDF \u003d ordersDF.na.fill(Map(\"days_since_prior_order\" -\u003e -1))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4. Join the remaining tables\n\nJoin the `ordersDF` and `productDetailsDF` to the `orderProductsDF` to form one single denormalized dataset"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDF \u003d orderProductsDF.join(updatedOrdersDF, Seq(\"order_id\"), \"left_outer\").join(productDetailsDF, Seq(\"product_id\"), \"left_outer\")\n\njoinedDF.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(joinedDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5. Drop Null\n\nDrop all rows with null values"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nonNullDF \u003d joinedDF.na.drop()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 6. Drop ID columns\n\nDrop the `eval_set` column and all the `id` columns"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val columns \u003d nonNullDF.columns.filter(c \u003d\u003e c.endsWith(\"_id\") || c.equals(\"eval_set\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cleanedDF \u003d nonNullDF.drop(columns: _*)"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(cleanedDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7. Save the cleaned dataframe\n\nSave `cleanedDF` in parquet format"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"instacart/instacart-clean.parquet\"\n\ncleanedDF.write.mode(\"overwrite\").parquet(outputPath)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Step 4: Basket Analysis/Profiling"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1. Most popular orders"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val orderCountsDF \u003d cleanedDF.groupBy(\"product_name\").agg(count(\"product_name\") as \"order_count\").orderBy(desc(\"order_count\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(orderCountsDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2. Peak Order Hour"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val orderHourDF \u003d cleanedDF.groupBy(\"order_hour_of_day\").agg(count(\"order_hour_of_day\") as \"order_count\").orderBy(desc(\"order_count\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(orderHourDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3. Peak Order Day"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val orderDayDF \u003d cleanedDF.groupBy(\"order_dow\").agg(count(\"order_dow\") as \"order_count\").orderBy(desc(\"order_count\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(orderDayDF)"
    }
  ]
}