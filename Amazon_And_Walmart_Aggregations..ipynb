{
  "metadata": {
    "name": "Amazon_And_Walmart_Aggregations",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// /user/rr4577_nyu_edu/amazon-clean.parquet\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val schema \u003d \"rating DOUBLE, category STRING, date DATE\""
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Reading the First Parquet files:\nval cleanDF \u003d spark.read.schema(schema).parquet(\"/user/rr4577_nyu_edu/amazon-clean.parquet\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mycleanedDF \u003d spark.read.schema(schema).parquet(\"/user/sc10670_nyu_edu/project/amazon-clean.parquet\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val combinedDF \u003d cleanDF.union(mycleanedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Remove rows where the category is \"Unknown\"\nval filteredDF \u003d combinedDF.filter(col(\"category\") \u003d!\u003d \"Unknown\")"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(filteredDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(filteredDF.summary())"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\n\n// Step 1: Filter the DataFrame for \"Gift Cards\" and convert the date column\nval giftCardsDF \u003d filteredDF.filter(col(\"category\") \u003d\u003d\u003d \"Gift Cards\")\n  .withColumn(\"review_date\", to_date(col(\"date\")))\n\n// Step 2: Filter for reviews from the last 5 years\nval last5YearsDF \u003d giftCardsDF.filter(col(\"review_date\").between(date_add(current_date(), -365 * 5), current_date()))\n\n// Step 3: Add year and week columns\nval weeklyReviewsDF \u003d last5YearsDF\n  .withColumn(\"year\", year(col(\"review_date\")))\n  .withColumn(\"week\", weekofyear(col(\"review_date\")))\n\n// Step 4: Group by year and week, and count the reviews\nval weeklyReviewCounts \u003d weeklyReviewsDF.groupBy(\"year\", \"week\")\n  .agg(count(\"*\").alias(\"review_count\"))\n  .orderBy(\"year\", \"week\")\n\n// Step 5: Display the results\nz.show(weeklyReviewCounts)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dowDF \u003d filteredDF.withColumn(\"rating_dow\", dayofweek(col(\"date\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\n\n// Filter data for years after 2018\nval filteredDF \u003d combinedDF.filter(year(to_date(col(\"date\"), \"yyyy-MM-dd\")) \u003e 2018)\n\n// Extract year and month\nval dfWithYearMonth \u003d filteredDF\n  .withColumn(\"year\", year(to_date(col(\"date\"), \"yyyy-MM-dd\")))\n  .withColumn(\"month\", month(to_date(col(\"date\"), \"yyyy-MM-dd\")))\n\n// Group by year and month, and count the number of ratings\nval ratingsByMonth \u003d dfWithYearMonth.groupBy(\"year\", \"month\")\n  .agg(count(\"rating\").alias(\"total_ratings\"))\n\n// Calculate the average number of ratings for each month across all years\nval avgRatingsByMonth \u003d ratingsByMonth.groupBy(\"month\")\n  .agg(avg(\"total_ratings\").alias(\"average_ratings\"))\n  .orderBy(\"month\")\n\n// Show the result\nz.show(avgRatingsByMonth)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(dowDF.limit(10))"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ratingDayDF \u003d dowDF.groupBy(\"rating_dow\").agg(count(\"rating_dow\") as \"rating_count\")"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(ratingDayDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val categoryRatingsDF \u003d dowDF.groupBy(\"rating_dow\", \"category\").agg(count(\"rating_dow\") as \"rating_count\")"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(categoryRatingsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "filteredDF.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ratingDistributionDF \u003d filteredDF.groupBy(\"rating\").count()\nz.show(ratingDistributionDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Top Categories by rating count\nval topCategoriesDF \u003d filteredDF.groupBy(\"category\").agg(count(\"rating\") as \"rating_count\").orderBy(desc(\"rating_count\"))\nz.show(topCategoriesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Trend of Ratings Over Time in Reverse Order of Year\nval ratingsTrendDF \u003d filteredDF.withColumn(\"year\", year(col(\"date\")))\n                               .groupBy(\"year\")\n                               .agg(count(\"rating\").alias(\"rating_count\"))\n                               .orderBy(desc(\"year\")) // Order by year in descending order\n\nz.show(ratingsTrendDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Average Ratings per category\nval avgRatingDF \u003d filteredDF.groupBy(\"category\").agg(avg(\"rating\") as \"avg_rating\")\nz.show(avgRatingDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Seasonal Ratings(Month wise analysis)\nval monthWiseDF \u003d filteredDF.withColumn(\"month\", month(col(\"date\")))\n                            .groupBy(\"month\")\n                            .agg(count(\"rating\") as \"rating_count\")\nz.show(monthWiseDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\n\n// Group by category and count the total number of ratings\nval totalRatingsByCategory \u003d combinedDF.groupBy(\"category\")\n  .agg(count(\"rating\").alias(\"total_ratings\"))\n  .orderBy(desc(\"total_ratings\")) // Order by total ratings in descending order\n\n// Show the result\nz.show(totalRatingsByCategory)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//HeatMaps of Ratings by Day of week and Month\nval dowMonthDF \u003d filteredDF.withColumn(\"day_of_week\", dayofweek(col(\"date\")))\n                           .withColumn(\"month\", month(col(\"date\")))\n                           .groupBy(\"day_of_week\", \"month\")\n                           .agg(count(\"rating\") as \"rating_count\")\nz.show(dowMonthDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// NOW WORKING ON THE WALMART DATA HERE ON AS WELL\n///user/sc10670_nyu_edu/project/cleaned-walmart-data.parquet\nval walmartDF \u003d spark.read.parquet(\"project/cleaned-walmart-data.parquet\")\nwalmartDF.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Day Wise Statistics:\n// Add a new column for day of the week extracted from \u0027order_date\u0027\nval walmartDFWithDay \u003d walmartDF.withColumn(\"day_of_week\", date_format(to_date(col(\"order_date\"), \"yyyy-MM-dd\"), \"EEEE\"))\n\n// Group data by day of the week and calculate trends\n// For example, calculate total orders, total profit, and average shipping cost by day of the week\nval trendsByDay \u003d walmartDFWithDay.groupBy(\"day_of_week\")\n  .agg(\n    count(\"*\").alias(\"total_orders\"),\n    sum(\"profit\").alias(\"total_profit\"),\n    avg(\"shipping_cost\").alias(\"average_shipping_cost\"),\n    sum(\"order_quantity\").alias(\"total_quantity\")\n  )\n  .orderBy(\"day_of_week\") // Sort by day of the week\n\n// Show the results\nz.show(trendsByDay)"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Number of Unique Cities per State\nval stateCitiesDF \u003d walmartDF.groupBy(\"state\")\n  .agg(countDistinct(\"city\").alias(\"number_of_unique_cities\"))\n  .orderBy(desc(\"number_of_unique_cities\"))\n  .limit(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(stateCitiesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//1. Customer Insights\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Age Group Analysis\nimport org.apache.spark.sql.functions._\n\nval ageGroupDF \u003d walmartDF\n  .withColumn(\"age_group\", when(col(\"customer_age\").cast(\"int\").between(0, 20), \"0-20\")\n    .when(col(\"customer_age\").cast(\"int\").between(21, 40), \"21-40\")\n    .when(col(\"customer_age\").cast(\"int\").between(41, 60), \"41-60\")\n    .otherwise(\"60+\"))\n  .groupBy(\"age_group\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\" // Corrected casting\n  )\nz.show(ageGroupDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val segmentTrendsDF \u003d walmartDF\n  .groupBy(\"customer_segment\")\n  .agg(sum(\"order_quantity\") as \"total_order_quantity\", sum(col(\"profit\").cast(\"double\")) as \"total_profit\")\nz.show(segmentTrendsDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// GEOGRAPHIC INSIGHTS\n// State-Wise Performance Ordered by Total Order Quantity (Top 10)\nval statePerformanceDF \u003d walmartDF\n  .groupBy(\"state\")\n  .agg(\n    sum(\"order_quantity\").alias(\"total_order_quantity\"),\n    sum(col(\"profit\").cast(\"double\")).alias(\"total_profit\"),\n    countDistinct(\"city\").alias(\"unique_customers\")\n  )\n  .orderBy(desc(\"total_order_quantity\")) // Order by total order quantity in descending order\n  .limit(10) // Show only the top 10 states\n\nz.show(statePerformanceDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cityTrendsDF \u003d walmartDF\n  .groupBy(\"city\")\n  .agg(\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n  .orderBy(desc(\"total_profit\"))\n  .limit(100)\n\nz.show(cityTrendsDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val regionPerformanceDF \u003d walmartDF\n  .groupBy(\"region\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(regionPerformanceDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//3. Sales and Profitability\n"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Monthly Trends\nval monthlyTrendsDF \u003d walmartDF\n  .withColumn(\"month\", month(col(\"order_date\")))\n  .groupBy(\"month\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(monthlyTrendsDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Discounts Impact on Profit\nval discountProfitCorrelationDF \u003d walmartDF\n  .select(\n    corr(col(\"discount\").cast(\"double\"), col(\"profit\").cast(\"double\")) as \"correlation_discount_profit\"\n  )\n\nz.show(discountProfitCorrelationDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//YoY Growth \nval yoyGrowthDF \u003d walmartDF\n  .withColumn(\"year\", year(col(\"order_date\")))\n  .groupBy(\"year\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(yoyGrowthDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Seasonal Trends\nval quarterlyTrendsDF \u003d walmartDF\n  .withColumn(\"quarter\", quarter(col(\"order_date\")))\n  .groupBy(\"quarter\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(quarterlyTrendsDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Weekday vs Weekend\nval dayOfWeekDF \u003d walmartDF\n  .withColumn(\"day_of_week\", date_format(col(\"order_date\"), \"E\"))\n  .withColumn(\"is_weekend\", when(col(\"day_of_week\").isin(\"Sat\", \"Sun\"), \"Weekend\").otherwise(\"Weekday\"))\n  .groupBy(\"is_weekend\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(dayOfWeekDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Cross Dimensional Insights\n//Region Segment Trends\nval regionSegmentTrendsDF \u003d walmartDF\n  .groupBy(\"region\", \"customer_segment\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(regionSegmentTrendsDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Age vs Region Trends\nval ageRegionTrendsDF \u003d walmartDF\n  .withColumn(\"age_group\", when(col(\"customer_age\").cast(\"int\").between(0, 20), \"0-20\")\n    .when(col(\"customer_age\").cast(\"int\").between(21, 40), \"21-40\")\n    .when(col(\"customer_age\").cast(\"int\").between(41, 60), \"41-60\")\n    .otherwise(\"60+\"))\n  .groupBy(\"region\", \"age_group\")\n  .agg(\n    sum(\"order_quantity\") as \"total_order_quantity\",\n    sum(col(\"profit\").cast(\"double\")) as \"total_profit\"\n  )\n\nz.show(ageRegionTrendsDF)\n"
    }
  ]
}