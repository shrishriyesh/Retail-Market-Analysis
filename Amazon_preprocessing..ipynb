{
  "metadata": {
    "name": "Amazon_preprocessing",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ratingsDF \u003d spark.read\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .csv(\"/user/sc10670_nyu_edu/project/*.csv.gz\")"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "ratingsDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(ratingsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val newratingsDF \u003d ratingsDF\n  .withColumn(\"source_file\", regexp_replace(\n    regexp_extract(input_file_name(), \"([^/]+$)\", 0),\n    \"\\\\.csv\", \"\"\n  ))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "newratingsDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(newratingsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val asinSchema \u003d \"parent_asin STRING, category STRING\""
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val asinSchema \u003d \"parent_asin STRING, category STRING\"\n\nval asinDF \u003d spark.read\n  .schema(asinSchema)\n  .csv(\"/user/sc10670_nyu_edu/project/asin.csv\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "asinDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(asinDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(s\"Number of records in the ratings dataframe: ${newratingsDF.count()}\")\nprintln(s\"Number of records in the asin dataframe: ${asinDF.count()}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(newratingsDF.summary())"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val missingRatingsDF \u003d newratingsDF.filter(newratingsDF.columns.map(c \u003d\u003e col(c).isNull).reduce(_ || _))\nprintln(s\"Number of records with null values in newratingsDF: ${missingRatingsDF.count()}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val missingAsinDF \u003d asinDF.filter($\"parent_asin\".isNull || $\"category\".isNull)\nprintln(s\"Number of records with null values in asinDF: ${missingAsinDF.count()}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mergedDF \u003d newratingsDF.join(asinDF, Seq(\"parent_asin\"), \"left_outer\")\n\nval nullData \u003d mergedDF.filter($\"category\".isNull)\n\n// Optional: Replace null values in `category` if needed\n//val filledDF \u003d mergedDF.na.fill(Map(\"category\" -\u003e \"Unknown\"))\n\n// Display the merged DataFrame or null rows\n//filledDF.show()\nnullData.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val updatedCategoriesDF \u003d mergedDF.withColumn(\n  \"category\",\n  when(col(\"category\").isNull, regexp_replace(col(\"source_file\"), \"_\", \" \")).otherwise(col(\"category\"))\n)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nonRedundantDF \u003d updatedCategoriesDF.drop(\"user_id\", \"parent_asin\", \"source_file\")"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cleanedDF \u003d nonRedundantDF.withColumn(\n  \"date\",\n  from_unixtime(col(\"timestamp\") / 1000).cast(\"date\")\n).drop(\"timestamp\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "cleanedDF.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"/user/sc10670_nyu_edu/project/amazon-clean.parquet\"\n\ncleanedDF.write.mode(\"overwrite\").parquet(outputPath)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catCountDF \u003d cleanedDF.groupBy(\"category\").agg(count(\"category\") as \"category_count\").orderBy(desc(\"category_count\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(catCountDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catRatingsDF \u003d cleanedDF\n  .groupBy(\"category\")\n  .agg(avg(\"rating\").as(\"avg_rating\"))\n  .orderBy(desc(\"avg_rating\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(catRatingsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val oldestDateDF\u003dcleanedDF.orderBy(\"date\")"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(oldestDateDF)"
    }
  ]
}